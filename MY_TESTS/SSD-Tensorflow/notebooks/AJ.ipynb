{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "from moviepy.editor import VideoFileClip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from preprocessing import ssd_vgg_preprocessing\n",
    "from nets import ssd_vgg_300, np_methods\n",
    "from notebooks import visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "slim = tf.contrib.slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_names = [\"background\", \"aeroplane\", \"bicycle\", \"bird\", \"boat\",\n",
    "               \"bottle\", \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\",\n",
    "               \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\", \"sheep\",\n",
    "               \"sofa\", \"train\", \"monitor\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "isess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Input placeholder.\n",
    "net_shape = (300, 300)\n",
    "data_format = 'NHWC'\n",
    "img_input = tf.placeholder(tf.uint8, shape=(None, None, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Evaluation pre-processing: resize to SSD net shape.\n",
    "image_pre, labels_pre, bboxes_pre, bbox_img = ssd_vgg_preprocessing.preprocess_for_eval(\n",
    "    img_input, None, None, net_shape, data_format, resize=ssd_vgg_preprocessing.Resize.WARP_RESIZE)\n",
    "image_4d = tf.expand_dims(image_pre, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the SSD model.\n",
    "ssd_net = ssd_vgg_300.SSDNet()\n",
    "with slim.arg_scope(ssd_net.arg_scope(data_format=data_format)):\n",
    "    predictions, localisations, _, _ = ssd_net.net(image_4d, is_training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Restore SSD model.\n",
    "ckpt_filename = '../checkpoints/ssd_300_vgg.ckpt'\n",
    "#ckpt_filename = '../checkpoints/VGG_VOC0712_SSD_300x300_ft_iter_120000.ckpt'\n",
    "isess.run(tf.global_variables_initializer())\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(isess, ckpt_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SSD default anchor boxes.\n",
    "ssd_anchors = ssd_net.anchors(net_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create unique and somewhat visually distinguishable bright\n",
    "# colors for the different classes.\n",
    "num_classes = len(class_names)\n",
    "class_colors = []\n",
    "for i in range(0, num_classes):\n",
    "    # This can probably be written in a more elegant manner\n",
    "    hue = 255*i/num_classes\n",
    "    col = np.zeros((1,1,3)).astype(\"uint8\")\n",
    "    col[0][0][0] = hue\n",
    "    col[0][0][1] = 128 # Saturation\n",
    "    col[0][0][2] = 255 # Value\n",
    "    cvcol = cv2.cvtColor(col, cv2.COLOR_HSV2BGR)\n",
    "    col = (int(cvcol[0][0][0]), int(cvcol[0][0][1]), int(cvcol[0][0][2]))\n",
    "    class_colors.append(col) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ssd_process_frame(img, select_threshold=0.5, nms_threshold=0.2):\n",
    "    \"\"\"Process a video frame through SSD network, apply NMS algorithm and draw bounding boxes.\n",
    "    \n",
    "    Arguments:\n",
    "      img: Numpy array containing an image.\n",
    "      select_threshold: Classification threshold (i.e. probability threshold for car detection).\n",
    "      nms_threshold: NMS threshold.\n",
    "    Return:\n",
    "      image with bounding boxes.\n",
    "    \"\"\"\n",
    "    to_draw = img\n",
    "    \n",
    "    # Run SSD network.\n",
    "    rimg, rpredictions, rlocalisations, rbbox_img = isess.run(\n",
    "        [image_4d, predictions, localisations, bbox_img],\n",
    "        feed_dict={img_input: to_draw})\n",
    "    \n",
    "    # Get classes and bboxes from the net outputs.\n",
    "    rclasses, rscores, rbboxes = np_methods.ssd_bboxes_select(\n",
    "            rpredictions, rlocalisations, ssd_anchors,\n",
    "            select_threshold=select_threshold, img_shape=net_shape, num_classes=21, decode=True)\n",
    "\n",
    "    # Remove other classes than cars.\n",
    "    idxes = (rclasses == 7)\n",
    "    #idxes = ((rclasses == 2) | (rclasses == 12))\n",
    "    rclasses = rclasses[idxes]\n",
    "    rscores = rscores[idxes]\n",
    "    rbboxes = rbboxes[idxes]\n",
    "    \n",
    "    rbboxes = np_methods.bboxes_clip(rbbox_img, rbboxes)\n",
    "    rclasses, rscores, rbboxes = np_methods.bboxes_sort(rclasses, rscores, rbboxes, top_k=400)\n",
    "    rclasses, rscores, rbboxes = np_methods.bboxes_nms(rclasses, rscores, rbboxes, nms_threshold=nms_threshold)\n",
    "    \n",
    "    # Resize bboxes to original image shape. Note: useless for Resize.WARP!\n",
    "    rbboxes = np_methods.bboxes_resize(rbbox_img, rbboxes)\n",
    "    \n",
    "    height = to_draw.shape[0]\n",
    "    width = to_draw.shape[1]\n",
    "\n",
    "    for i in range(rclasses.shape[0]):\n",
    "        cls_id = int(rclasses[i])\n",
    "        if cls_id >= 0:\n",
    "            score = rscores[i]\n",
    "            ymin = int(rbboxes[i, 0] * height)\n",
    "            xmin = int(rbboxes[i, 1] * width)\n",
    "            ymax = int(rbboxes[i, 2] * height)\n",
    "            xmax = int(rbboxes[i, 3] * width)\n",
    "            cv2.rectangle(to_draw, (xmin, ymin), (xmax, ymax), class_colors[cls_id], 2)\n",
    "\n",
    "            text_top = (xmin, ymin)\n",
    "            text_bot = (xmin + 80, ymin + 15)\n",
    "            text_pos = (xmin + 5, ymin + 10)\n",
    "            cv2.rectangle(to_draw, text_top, text_bot, class_colors[cls_id], -1)\n",
    "            \n",
    "            text = class_names[cls_id] + \" \" + ('%.2f' % score)\n",
    "            cv2.putText(to_draw, text, text_pos, cv2.FONT_HERSHEY_SIMPLEX, 0.35, (0,0,0), 1)\n",
    "\n",
    "    return to_draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Selection parameters.\n",
    "select_threshold=0.17\n",
    "nms_threshold=0.45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video challenge_video_cars.mp4\n",
      "[MoviePy] Writing video challenge_video_cars.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 485/485 [00:50<00:00,  9.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: challenge_video_cars.mp4 \n",
      "\n",
      "Wall time: 50.9 s\n"
     ]
    }
   ],
   "source": [
    "clip1 = VideoFileClip(\"challenge_video.mp4\")\n",
    "white_clip = clip1.fl_image(lambda x: ssd_process_frame(x, select_threshold, nms_threshold))\n",
    "%time white_clip.write_videofile('challenge_video_cars.mp4', audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tfgpu]",
   "language": "python",
   "name": "conda-env-tfgpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
