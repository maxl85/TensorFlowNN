{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Embedding for the visualizer\n",
    "\n",
    "This notebook shows how to create embeddings for the PCA / tSNE visualizer in tensorboard. We use a trained VGG16 network and feed CIFAR images through it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import scipy.misc\n",
    "import pickle\n",
    "%matplotlib inline\n",
    "import tensorflow.contrib.slim as slim\n",
    "import tensorflow.contrib.slim.nets as nets\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.tensorboard.plugins import projector\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading of the data\n",
    "\n",
    "The 32x32 CIFAR images we use here can be obtained from: http://www.cs.toronto.edu/~kriz/cifar.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000,), (10000, 32, 32, 3))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = './cifar-10-batches-py/test_batch'\n",
    "f = open(path, 'rb')\n",
    "data = pickle.load(f, encoding='bytes')\n",
    "imgs = data[b'data']\n",
    "imgs = np.transpose(np.reshape(imgs,(-1,32,32,3), order='F'),axes=(0,2,1,3)) #order batch,x,y,color\n",
    "y = np.asarray(data[b'labels'], dtype='uint8')\n",
    "y.shape, imgs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the models\n",
    "\n",
    "We use a trained VGG16 network. As a first step we download the VGG16 weights (filename vgg_16.tar.gz) from [here](https://github.com/tensorflow/models/blob/master/slim/README.md#Pretrained) and extract it. After extraction you should get a file named vgg_16.ckpt.\n",
    "\n",
    "For more details refere to http://randomthoughtsonr.blogspot.de/2016/11/image-classification-in-r-using-trained.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of variables to restore 32\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "images = tf.placeholder(tf.float32, [None, None, None, 3])\n",
    "imgs_scaled = tf.image.resize_images(images, (224,224))\n",
    "slim.nets.vgg.vgg_16(imgs_scaled, is_training=False)\n",
    "variables_to_restore = slim.get_variables_to_restore()\n",
    "print('Number of variables to restore {}'.format(len(variables_to_restore)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init_assign_op, init_feed_dict = slim.assign_from_checkpoint('./vgg_16.ckpt', variables_to_restore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(init_assign_op, init_feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3, 32, 32, 3), (3, 1, 1, 4096))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = tf.get_default_graph()\n",
    "feed = g.get_tensor_by_name('Placeholder:0')\n",
    "fetch = g.get_tensor_by_name('vgg_16/fc6/BiasAdd:0')\n",
    "\n",
    "# Feeding 3 images through the net just for testing\n",
    "feed_vals = imgs[0:3]\n",
    "res = sess.run(fetch, feed_dict={feed:feed_vals})\n",
    "np.shape(feed_vals), res.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the embedding\n",
    "\n",
    "We now create a $N \\times p$ matrix holding the embeddings, for the N images. For simplycify, we do this by feeding the images one after another through the network (of course we could have also used minibatches). We store this matrix in `EMB` to use it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n",
      "450\n",
      "500\n",
      "550\n",
      "600\n",
      "650\n",
      "700\n",
      "750\n",
      "800\n",
      "850\n",
      "900\n",
      "950\n"
     ]
    }
   ],
   "source": [
    "N = imgs.shape[0]\n",
    "N = 1000 #For testing \n",
    "p = res.shape[3]\n",
    "\n",
    "EMB = np.zeros((N, p), dtype='float32')\n",
    "for i in range(N): #Of course you could do mini-batches\n",
    "    EMB[i] = sess.run(fetch, feed_dict={feed: imgs[i:i+1,:]})\n",
    "    if (i % 50 == 0 or i < 5):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing out the embedding matrix\n",
    "We now write out the embedding matrix in the proper format needed for the visualizer. If you don't want images or meta data, just comment out the respective parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./tmp/dumm\\\\model2.ckpt-1'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LOG_DIR = 'c:\\\\Users\\\\Main\\\\Documents\\\\Anaconda\\\\MY_TESTS\\\\TensorBoard\\\\CIFAR\\\\tmp\\\\dumm\\\\'\n",
    "\n",
    "# The embedding variable, which needs to be stored\n",
    "# Note this must a Variable not a Tensor!\n",
    "embedding_var = tf.Variable(EMB,  name='Embedding_of_fc6')\n",
    "sess.run(embedding_var.initializer)\n",
    "summary_writer = tf.summary.FileWriter(LOG_DIR)\n",
    "config = projector.ProjectorConfig()\n",
    "embedding = config.embeddings.add()\n",
    "embedding.tensor_name = embedding_var.name\n",
    "\n",
    "# Comment out if you don't have metadata\n",
    "embedding.metadata_path = os.path.join(LOG_DIR, 'metadata.tsv')\n",
    "\n",
    "# Comment out if you don't want sprites\n",
    "embedding.sprite.image_path = os.path.join(LOG_DIR, 'sprite.png')\n",
    "embedding.sprite.single_image_dim.extend([imgs.shape[1], imgs.shape[1]])\n",
    "\n",
    "projector.visualize_embeddings(summary_writer, config)\n",
    "saver = tf.train.Saver([embedding_var])\n",
    "saver.save(sess, os.path.join(LOG_DIR, 'model2.ckpt'), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation of the meta data (labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names = ['plane','auto','bird','cat','deer','dog','frog','horse','ship','truck']\n",
    "metadata_file = open(os.path.join(LOG_DIR, 'metadata.tsv'), 'w')\n",
    "metadata_file.write('Name\\tClass\\n')\n",
    "for i in range(N):\n",
    "    metadata_file.write('%06d\\t%s\\n' % (i, names[y[i]]))\n",
    "metadata_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Taken from: https://github.com/tensorflow/tensorflow/issues/6322\n",
    "def images_to_sprite(data):\n",
    "    \"\"\"Creates the sprite image along with any necessary padding\n",
    "\n",
    "    Args:\n",
    "      data: NxHxW[x3] tensor containing the images.\n",
    "\n",
    "    Returns:\n",
    "      data: Properly shaped HxWx3 image with any necessary padding.\n",
    "    \"\"\"\n",
    "    if len(data.shape) == 3:\n",
    "        data = np.tile(data[...,np.newaxis], (1,1,1,3))\n",
    "    data = data.astype(np.float32)\n",
    "    min = np.min(data.reshape((data.shape[0], -1)), axis=1)\n",
    "    data = (data.transpose(1,2,3,0) - min).transpose(3,0,1,2)\n",
    "    max = np.max(data.reshape((data.shape[0], -1)), axis=1)\n",
    "    data = (data.transpose(1,2,3,0) / max).transpose(3,0,1,2)\n",
    "    # Inverting the colors seems to look better for MNIST\n",
    "    #data = 1 - data\n",
    "\n",
    "    n = int(np.ceil(np.sqrt(data.shape[0])))\n",
    "    padding = ((0, n ** 2 - data.shape[0]), (0, 0),\n",
    "            (0, 0)) + ((0, 0),) * (data.ndim - 3)\n",
    "    data = np.pad(data, padding, mode='constant',\n",
    "            constant_values=0)\n",
    "    # Tile the individual thumbnails into an image.\n",
    "    data = data.reshape((n, n) + data.shape[1:]).transpose((0, 2, 1, 3)\n",
    "            + tuple(range(4, data.ndim + 1)))\n",
    "    data = data.reshape((n * data.shape[1], n * data.shape[3]) + data.shape[4:])\n",
    "    data = (data * 255).astype(np.uint8)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sprite = images_to_sprite(imgs)\n",
    "scipy.misc.imsave(os.path.join(LOG_DIR, 'sprite.png'), sprite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tfgpu]",
   "language": "python",
   "name": "conda-env-tfgpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
